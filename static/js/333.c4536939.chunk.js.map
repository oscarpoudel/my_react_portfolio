{"version":3,"file":"static/js/333.c4536939.chunk.js","mappings":"kJAiDA,UA7C+B,WAC7B,OACE,iBAAKA,UAAU,yCAAf,WAEE,sCACA,sCACW,mDADX,8WAGA,0UAC0S,kDAD1S,2GAIA,iBAAKA,UAAU,YAAf,WACE,gBAAKC,IAAI,kHAAkHC,IAAI,4DAA4DF,UAAU,kBACrM,gBAAKC,IAAI,sHAAsHC,IAAI,yDAAyDF,UAAU,kBACtM,gBAAKC,IAAI,0HAA0HC,IAAI,qCAAqCF,UAAU,kBACtL,gBAAKC,IAAI,6HAA6HC,IAAI,+CAA+CF,UAAU,qBAErM,gBAAKA,UAAU,UAAf,uLAIA,2EACA,gUAGA,iTAIA,0CACA,2BACE,2BAAI,8EAAJ,6EACA,2BAAI,8DAAJ,sGACA,2BAAI,kEAAJ,0HAGF,wCACA,8Q","sources":["components/Detailslist/Project6.jsx"],"sourcesContent":["import React from 'react'\r\nimport \"./Project1.scss\"\r\n\r\n\r\nconst ProjectCalibrateCamera = () => {\r\n  return (\r\n    <div className=\"styled-project project-details-content\">\r\n      {/* <h2>Theoretical Foundations of Camera Calibration</h2> */}\r\n      <h4>Overview</h4>\r\n      <p>\r\n        Accurate <strong>camera calibration</strong> is fundamental in robotics and computer vision. The goal is to determine the internal geometry and lens distortion parameters of a camera—its “intrinsics” which map 3D world points to their measured pixel coordinates. Without precise calibration, spatial measurements, 3D reconstructions, and robot navigation all suffer from systematic error.\r\n      </p>\r\n      <p>\r\n        The classic approach uses a flat checkerboard pattern, observed from various orientations and distances. Each pose yields a set of observed image points whose known 3D locations—given by the checkerboard grid; allow robust estimation of camera parameters by minimizing the reprojection error via <strong>bundle adjustment</strong>. Multiple diverse viewpoints across the field of view are critical for a well-conditioned solution.\r\n      </p>\r\n\r\n      <div className=\"image-row\">\r\n        <img src=\"https://raw.githubusercontent.com/oscarpoudel/get_calibrate_camera/main/images/2.camera_calibration_process.png\" alt=\"Detecting checkerboard corners in the calibration process\" className=\"scaled-image\"/>\r\n        <img src=\"https://raw.githubusercontent.com/oscarpoudel/get_calibrate_camera/main/images/2.camera_calibration_process_iii.png\" alt=\"Checkerboard grid detected and overlaid on input image\" className=\"scaled-image\"/>\r\n        <img src=\"https://raw.githubusercontent.com/oscarpoudel/get_calibrate_camera/main/images/3.camera_calibration_output_matrices.png\" alt=\"Calibration results: camera matrix\" className=\"scaled-image\"/>\r\n        <img src=\"https://raw.githubusercontent.com/oscarpoudel/get_calibrate_camera/main/images/3.camera_calibration_output_matrices_ii.png\" alt=\"Calibration results: distortion coefficients\" className=\"scaled-image\"/>\r\n      </div>\r\n      <div className=\"caption\">\r\n        Left: Detecting checkerboard patterns during calibration. Middle: Visual feedback showing corner extraction. Right: Output intrinsic matrix and distortion coefficients.\r\n      </div>\r\n\r\n      <h4>Automated and Visualized Calibration in ROS 2</h4>\r\n      <p>\r\n        This toolkit automates the classical process using ROS 2 nodes. The calibration node collects images from a connected camera; each time a sufficiently different checkerboard pose is detected, the image is accepted, ensuring variability in angle, distance, and position for accurate coverage.\r\n      </p>\r\n      <p>\r\n        Real-time overlays and progress bars guide the user. Once enough images have been acquired, calibration is performed, calculating the focal length, principal point, and distortion parameters. The results can be visualized and exported for direct use in robot vision pipelines.\r\n      </p>\r\n\r\n      <h4>Significance</h4>\r\n      <ul>\r\n        <li><strong>Enables metric 3D measurements from 2D images</strong>—this is foundational for tasks like SLAM, AR, or grasp planning.</li>\r\n        <li><strong>Reduces re-calibration effort</strong> by automating data collection variability and providing visual diagnosis for outlier patterns.</li>\r\n        <li><strong>Integrates with the ROS ecosystem</strong>—making extrinsic calibration (sensor mounting relationships) reliable when paired with precise intrinsics.</li>\r\n      </ul>\r\n\r\n      <h4>Conclusion</h4>\r\n      <p>\r\n        By combining theoretical calibration methods with modern ROS 2 automation and feedback, this package ensures robust, reproducible estimation of camera parameters—building a solid basis for all downstream robotic vision applications.\r\n      </p>\r\n    </div>\r\n  )\r\n}\r\n\r\nexport default ProjectCalibrateCamera"],"names":["className","src","alt"],"sourceRoot":""}