"use strict";(self.webpackChunkmy_portfolio=self.webpackChunkmy_portfolio||[]).push([[780],{780:function(e,i,s){s.r(i);s(791),s(750);var t=s(184);i.default=function(){return(0,t.jsxs)("div",{className:"project-details-content styled-project",children:[(0,t.jsx)("h4",{children:"Problem Statement"}),(0,t.jsxs)("p",{children:["Accurate real-world navigation requires estimating motion from camera video alone. The ",(0,t.jsx)("strong",{children:"VSLAM_light"})," project implements a simple monocular visual odometry pipeline, aiming for robust pose estimation from image sequences using feature tracking and Kalman filtering."]}),(0,t.jsxs)("ul",{children:[(0,t.jsx)("li",{children:"Estimate real-time camera trajectories from monocular images"}),(0,t.jsx)("li",{children:"Use only consumer-level datasets, hardware, and open-source tools"})]}),(0,t.jsx)("h4",{children:"Research Objectives"}),(0,t.jsxs)("ul",{children:[(0,t.jsx)("li",{children:"Develop a minimal visual odometry pipeline leveraging classical computer vision"}),(0,t.jsx)("li",{children:"Apply and compare feature tracking algorithms and smoothing filters"}),(0,t.jsx)("li",{children:"Support evaluation against ground-truth and KITTI-format datasets"})]}),(0,t.jsx)("h4",{children:"System Model"}),(0,t.jsxs)("ul",{children:[(0,t.jsxs)("li",{children:[(0,t.jsx)("strong",{children:"Input:"})," Monocular image stream, camera calibration file, ground-truth trajectory"]}),(0,t.jsxs)("li",{children:[(0,t.jsx)("strong",{children:"Processing pipeline:"}),(0,t.jsxs)("ul",{children:[(0,t.jsx)("li",{children:"Corner detection using Shi-Tomasi"}),(0,t.jsx)("li",{children:"Feature tracking via pyramidal Lucas-Kanade optical flow"}),(0,t.jsx)("li",{children:"Pose estimation by essential matrix calculation"}),(0,t.jsx)("li",{children:"Trajectory smoothing using a constant-velocity Kalman filter"})]})]}),(0,t.jsxs)("li",{children:[(0,t.jsx)("strong",{children:"Output:"})," Live plots of feature matches and estimated vs ground-truth trajectories"]})]}),(0,t.jsx)("h4",{children:"Methodology"}),(0,t.jsx)("p",{children:"The pipeline sequentially detects/filters features, tracks them across frames, and estimates 3D motion increments. Kalman filtering improves trajectory quality by integrating prior motion models with noisy estimates."}),(0,t.jsxs)("ul",{children:[(0,t.jsx)("li",{children:"Robust corner detection and pruning"}),(0,t.jsx)("li",{children:"Optical flow tracking (frame-to-frame)"}),(0,t.jsx)("li",{children:"Relative pose estimation via essential matrix decomposition"}),(0,t.jsx)("li",{children:"Constant-velocity Kalman filter for trajectory smoothing"})]}),(0,t.jsx)("h4",{children:"Results"}),(0,t.jsx)("p",{children:"The system accurately tracks and plots the estimated camera path against ground truth, showing clear visualizations of tracked features and trajectory comparison."}),(0,t.jsxs)("ul",{children:[(0,t.jsx)("li",{children:"Error is minimized with Kalman filtering, providing smoother and more reliable estimates"}),(0,t.jsx)("li",{children:"Real-time visualizations support live debugging and assessment of tracking performance"})]}),(0,t.jsx)("img",{src:"https://raw.githubusercontent.com/oscarpoudel/VSLAM_light/main/image/2.png",alt:"Feature tracking overlay",className:"scaled-image"}),(0,t.jsx)("img",{src:"https://raw.githubusercontent.com/oscarpoudel/VSLAM_light/main/image/1.png",alt:"Estimated and ground-truth trajectories",className:"scaled-image"}),(0,t.jsx)("h4",{children:"Key Insights"}),(0,t.jsxs)("ul",{children:[(0,t.jsx)("li",{children:"Classical feature-based odometry remains powerful for well-behaved datasets"}),(0,t.jsx)("li",{children:"Kalman filtering provides significant improvements in estimated trajectory smoothness"}),(0,t.jsx)("li",{children:"Live visualization helps tune and debug each processing stage"})]}),(0,t.jsx)("h4",{children:"Practical Considerations"}),(0,t.jsxs)("ul",{children:[(0,t.jsx)("li",{children:"Monocular VO cannot recover scale in absolute terms\u2014ground-truth needed for evaluation"}),(0,t.jsx)("li",{children:"Sensitivity to lighting and scene structure may affect feature tracking"}),(0,t.jsx)("li",{children:"Real deployment needs outlier rejection and possibly inertial fusion"})]}),(0,t.jsxs)("p",{children:[(0,t.jsx)("strong",{children:"Conclusion:"}),"VSLAM_light shows a practical, approachable, and open-source baseline for visual odometry research, supporting education, prototyping, and rapid development on standard datasets."]})]})}},750:function(){}}]);
//# sourceMappingURL=780.3da4d6dd.chunk.js.map