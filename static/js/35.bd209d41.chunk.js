"use strict";(self.webpackChunkmy_portfolio=self.webpackChunkmy_portfolio||[]).push([[35],{271:function(e,s,i){i.r(s),i.d(s,{default:function(){return d}});i(791);var a=i.p+"static/media/1_methodology.5af96b6040fb145e975d.png",n=i.p+"static/media/2_simulation_setup.52658b8ebd288749b112.png",r=i.p+"static/media/3_target_system.8ebf5742d9a0dd541ff7.png",t=i.p+"static/media/4_res1.22ccff3b3a967cbc343d.png",l=i.p+"static/media/5_res2.54a4070fdf69df11b308.png",c=i.p+"static/media/6_gaze_pid.c2a5ad172f1a0aa0e37c.png",o=(i(750),i(184)),d=function(){return(0,o.jsxs)("div",{className:"project-details-content styled-project",children:[(0,o.jsx)("h4",{children:"Problem Statement"}),(0,o.jsx)("p",{children:"Navigating UAVs in confined spaces presents challenges such as limited maneuverability, operator fatigue, and the precision required to avoid collisions. Traditional systems may not capture the operator\u2019s true intent\u2014especially for non-professional users."}),(0,o.jsx)("h4",{children:"Research Objectives"}),(0,o.jsxs)("ul",{children:[(0,o.jsx)("li",{children:"Develop a gaze-assisted Crazyflie teleoperation system in simulation"}),(0,o.jsx)("li",{children:"Compare traditional and gaze-assisted methods"}),(0,o.jsx)("li",{children:"Analyze integration and performance constraints in real time"})]}),(0,o.jsx)("h4",{children:"State of the Art"}),(0,o.jsxs)("ul",{children:[(0,o.jsxs)("li",{children:[(0,o.jsx)("strong",{children:"GPA-Teleoperation Framework:"})," Aligns drone path with operator\u2019s gaze"]}),(0,o.jsxs)("li",{children:[(0,o.jsx)("strong",{children:"GazeRace Method:"})," Eye-gaze control achieving comparable performance to manual methods"]})]}),(0,o.jsx)("h4",{children:"System Workflow"}),(0,o.jsxs)("ul",{children:[(0,o.jsx)("li",{children:"RealEye for gaze data"}),(0,o.jsx)("li",{children:"Joystick input"}),(0,o.jsx)("li",{children:"Webots simulator with Crazyflie drone"}),(0,o.jsx)("li",{children:"PID controller integration"}),(0,o.jsx)("li",{children:"Metrics: Task time, accuracy, latency, success rate"})]}),(0,o.jsx)("div",{className:"image-row",children:(0,o.jsx)("img",{src:n,alt:"Simulation Environment",className:"scaled-image"})}),(0,o.jsx)("h4",{children:"Methodology"}),(0,o.jsxs)("ul",{children:[(0,o.jsx)("li",{children:"Webots simulator with an indoor environment"}),(0,o.jsx)("li",{children:"Crazyflie open-source drone used for navigation"}),(0,o.jsx)("li",{children:"Target point system with task switching on successful reach"}),(0,o.jsx)("li",{children:"Gaze input denoised and mapped to drone PID controller"})]}),(0,o.jsx)("img",{src:a,alt:"Methodology Diagram",className:"scaled-image"}),(0,o.jsx)("h4",{children:"Target System"}),(0,o.jsxs)("div",{className:"image-row",children:[(0,o.jsx)("img",{src:r,alt:"Target System",className:"scaled-image"}),(0,o.jsx)("img",{src:c,alt:"Gaze to PID mapping",className:"scaled-image"})]}),(0,o.jsx)("h4",{children:"Key Metrics"}),(0,o.jsxs)("ul",{children:[(0,o.jsxs)("li",{children:[(0,o.jsx)("strong",{children:"Task Completion Time:"})," ~12% faster with gaze-assisted control"]}),(0,o.jsxs)("li",{children:[(0,o.jsx)("strong",{children:"Control Inputs:"})," 32% fewer with gaze support"]}),(0,o.jsxs)("li",{children:[(0,o.jsx)("strong",{children:"Latency:"})," Gaze system incurs ~50% more latency (15ms vs. 7ms)"]}),(0,o.jsxs)("li",{children:[(0,o.jsx)("strong",{children:"Task Success Rate:"})," Similar (~85%) in both methods"]})]}),(0,o.jsx)("img",{src:t,alt:"Results 1",className:"scaled-image"}),(0,o.jsx)("img",{src:l,alt:"Results 2",className:"scaled-image"}),(0,o.jsx)("h4",{children:"Key Insights"}),(0,o.jsxs)("ul",{children:[(0,o.jsx)("li",{children:"Gaze reduces workload and control complexity"}),(0,o.jsx)("li",{children:"Latency trade-off must be optimized for dynamic tasks"}),(0,o.jsx)("li",{children:"Operator learning curve exists for fine control via gaze"})]}),(0,o.jsx)("h4",{children:"Practical Considerations"}),(0,o.jsxs)("ul",{children:[(0,o.jsx)("li",{children:"Synchronization between gaze and controls is critical"}),(0,o.jsx)("li",{children:"Optimized gaze processing pipelines are essential"}),(0,o.jsx)("li",{children:"Scalability to multi-UAV or real-world scenarios requires further exploration"})]}),(0,o.jsxs)("p",{children:[(0,o.jsx)("strong",{children:"Conclusion:"})," Gaze-assisted teleoperation shows promise in reducing manual effort and improving navigational efficiency, but needs further development for latency and dynamic adaptability."]})]})}},750:function(){}}]);
//# sourceMappingURL=35.bd209d41.chunk.js.map